import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as l,a as e,d as t,f as s,e as h,w as p,r as k,o as d}from"./app-CHBNztBQ.js";const r="/img/HADOOP-ECOSYSTEM-Edureka.png",g="/img/Doug-Cutting.jpg",A="/img/hdfs%E6%9E%B6%E6%9E%84.png",c="/img/hdfs%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.png",o="/img/hdfs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8.svg",y="/img/hdfs-namenode.svg",B="/img/hdfs-edits.svg",F="/img/hdfs-fsimage.svg",v="/img/hdfs-fsimage-roll.png",m="/img/hdfs-%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5.png",u="/img/hdfs-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96.png",b="/img/hadoop-yarn%E8%B0%83%E5%BA%A6.svg",D="/img/hadoop-yarn%E6%9E%B6%E6%9E%84.svg",f="/img/hadoop-hive%E4%BB%8B%E7%BB%8D.png",C="/img/hadoop-hive-architectrue.png",E="/img/hadoop-hive%E5%88%86%E5%8C%BA%E5%88%86%E6%A1%B6.svg",S={};function x(N,i){const a=k("RouteLink");return d(),l("div",null,[i[2]||(i[2]=e('<h2 id="大数据" tabindex="-1"><a class="header-anchor" href="#大数据"><span>大数据</span></a></h2><p>人类的行为及产生的事件的一种记录称之为数据，对数据的内容进行深入分析，可以更好的帮助了解事和物在现实世界的运行规律。<strong>大数据</strong>就是对超大规模的数据进行处理并挖掘出数据背后价值的技术体系，是信息化时代的基础支撑，以数据为生活赋能。</p><p>随着科技的发展，大数据技术已经成为从事数据分析、机器学习、人工智能等领域的重要工具。大数据技术涵盖了数据的采集、存储、处理、分析和可视化等方面，包括分布式存储系统（如Hadoop、Spark）、分布式计算框架、机器学习算法、数据挖掘工具等。大数据分析可以帮助企业和组织在海量数据中发现有价值的信息，做出更明智的决策。</p><h3 id="_5v-特性" tabindex="-1"><a class="header-anchor" href="#_5v-特性"><span>5V 特性</span></a></h3><p>大数据通常具有五个主要特点，即 5V：</p><ol><li><p><strong>Volume 体积大：</strong> 大数据集合通常包含海量的数据，这可能涉及到数十TB、PB、甚至EB级别的数据量，传统的数据库和数据处理工具难以有效地处理如此庞大的数据。</p></li><li><p><strong>Variety 种类多：</strong> 大数据不仅包括结构化数据（如关系数据库中的表格数据），还包括非结构化数据（例如文本、图像、音频、视频等）和半结构化数据，这些不同类型的数据需要采用不同的处理方式。</p></li><li><p><strong>Value 价值密度低：</strong> 大数据虽然信息海量，但是价值密度低，深度复杂的挖掘分析需要机器学习参与。</p></li><li><p><strong>Velocity 速度快：</strong> 大数据集合的数据产生速度通常很快，需要实时或近实时地进行处理和分析。例如，社交媒体、传感器、日志文件等数据源都能够以很高的速度产生数据。</p></li><li><p><strong>Veracity 质量要求高：</strong> 大数据需要确保数据的准确性、可依赖性。</p></li></ol><p>总结下来，大数据就是<strong>从海量的高增长、多类别、低信息密度的数据中挖掘出高质量的结果</strong>。</p><h3 id="生态体系" tabindex="-1"><a class="header-anchor" href="#生态体系"><span>生态体系</span></a></h3><p>从大数据的特性出发，我们可以得到大数据的核心工作有三个：</p><ol><li><p><strong>数据存储：</strong> 妥善存储海量待处理数据</p><ul><li>HDFS：大数据体系中使用最为广泛的分布式存储技术</li><li>HBase：基于 HDFS 之上，使用非常广泛的 NoSQL KV 型数据库技术</li><li>KUDU：使用较多的分布式存储引擎</li><li>云平台存储引擎，如阿里云OSS、AWS-S3...</li></ul></li><li><p><strong>数据计算：</strong> 从海量数据中计算出背后的价值</p><ul><li>MapReduce：最早一代的大数据分布式计算引擎，对大数据的发展做出了卓越的贡献</li><li>Hive：基于 MapReduce，以 SQL 为主要开发语言的分布式计算框架</li><li>Spark：目前全球范围内最火热的分布式内存计算引擎</li><li>Flink：也是广泛使用的分布式内存计算引擎，特别是在实时流计算领域占据了大多数的国内市场</li></ul></li><li><p><strong>数据传输：</strong> 协助在各个环节中完成海量数据的传输</p><ul><li>Kafka：分布式的消息系统，可以完成海量规模的数据传输工作</li><li>Pulsar：同样是一款使用广泛的分布式消息系统</li><li>Flume：一款流式数据采集工具，可以从非常多的数据源中完成数据采集传输的任务</li><li>Sqoop：一款ETL（Extract, Transform, Load）工具，可以协助大数据体系和关系型数据库之间进行数据传输</li></ul></li></ol><figure><img src="'+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="hadoop" tabindex="-1"><a class="header-anchor" href="#hadoop"><span>Hadoop</span></a></h3><p><a href="https://hadoop.apache.org/" target="_blank" rel="noopener noreferrer">Hadoop</a> 是 Apache 软件基金会在 2008 年开源的分布式数据存储、计算、资源调度为一体的大数据框架，提供了一种处理大规模数据集，并且可靠、可扩展的分布式计算解决方案，可以借助Hadoop构建大规模服务器集群，完成海量数据的存储和计算。Hadoop 已经成为大数据处理领域的事实标准之一，被广泛应用于企业和科研机构。</p><p>Hadoop 主要包括三个核心模块：</p><ul><li><p><strong>HDFS</strong>：Hadoop Distributed File System 分布式文件系统，设计用于存储大规模数据集，具有高可靠性、高可用性、高容错性的特点。</p></li><li><p><strong>MapReduce</strong>：Hadoop 分布式计算框架，一种基于<em>分而治之</em>的思想，用于处理和生成大规模数据集的分布式计算框架。</p></li><li><p><strong>YARN</strong>：Yet Another Resource Negotiator 分布式内存资源调度组件，用于资源管理和作业调度，可供用户整体调度大规模集群的资源使用。</p></li></ul><blockquote><p>Hadoop 的创始人是雅虎的 Doug Cutting，起源于 <em>Nutch</em> 这个全网搜索引擎项目，并借鉴了 Google 的三篇 paper：</p><ul><li><a href="https://dl.acm.org/doi/pdf/10.1145/945445.945450" target="_blank" rel="noopener noreferrer">The Google file system</a></li><li><a href="https://dl.acm.org/doi/abs/10.1145/1327452.1327492" target="_blank" rel="noopener noreferrer">MapReduce: Simpliﬁed Data Processing on Large Clusters</a></li><li><a href="https://dl.acm.org/doi/abs/10.1145/1365815.1365816" target="_blank" rel="noopener noreferrer">Bigtable: A Distributed Storage System for Structured Data</a><img src="'+g+'" alt="" loading="lazy"></li></ul></blockquote><h2 id="hdfs" tabindex="-1"><a class="header-anchor" href="#hdfs"><span>HDFS</span></a></h2><p>在大数据时代，数据量是非常大的，传统的单机存储、单机计算无法满足性能需求，因此就需要分布式存储技术，通过增加机器数量来满足大规模数据存储和处理的需求，具有高可靠性、高扩展性、数据一致性、高性能的优点。</p><p>既然涉及了分布式，自然就有去中心化、中心化两种模式，在大数据框架中，大多数都是采用的中心化模式（主从模式），即有一个中心节点来统筹其它服务器的工作。HDFS（Hadoop Distributed File System）就是 Hadoop 技术栈内提供的基于主从的分布式数据存储解决方案，可以在多台服务器上构建存储集群，存储海量数据。</p><h3 id="基础架构" tabindex="-1"><a class="header-anchor" href="#基础架构"><span>基础架构</span></a></h3><p>HDFS 集群节点主要分为三个角色，分别都是一个独立的进程：</p><ul><li>NameNode：主角色，负责管理整个文件系统</li><li>SecondaryNameNode：辅助角色，帮助 NameNode 完成元数据整理工作</li><li>DataNode：从角色，负责数据的存取</li></ul><figure><img src="'+A+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="安装配置" tabindex="-1"><a class="header-anchor" href="#安装配置"><span>安装配置</span></a></h3><p>安装过程略，hadoop 目录包括 bin 二进制程序，etc 配置文件，sbin 管理员程序等常规目录结构，主要配置文件包括：</p><ul><li>workers：配置从节点（DataNode）有哪些</li><li><a href="http://hadoop-env.sh" target="_blank" rel="noopener noreferrer">hadoop-env.sh</a>：配置Hadoop的相关环境变量</li><li>core-site.xml：Hadoop核心配置文件</li><li>hdfs-site.xml：HDFS核心配置文件</li></ul><p>安装完成后，可以通过<code>sbin/start-dfs.sh</code>和<code>sbin/stop-dfs.sh</code>统一启动/停止 HDFS 服务，脚本执行以下步骤：</p><ol><li>在执行此脚本的机器上，启动/停止 SecondaryNameNode</li><li>读取core-site.xml内容（fs.defaultFS项），确认NameNode所在机器，启动/停止 NameNode</li><li>读取workers内容，确认DataNode所在机器，启动/停止全部 DataNode</li></ol><p>除了统一启停之外，也可以通过脚本单独控制所在机器的 HDFS 进程启停：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sbin/hadoop-daemon.sh</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> start</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">status</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">stop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> namenode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">secondarynamenode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">datanode</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">bin/hdfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --daemon</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> start</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">status</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">stop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> namenode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">secondarynamenode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">datanode</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="文件操作" tabindex="-1"><a class="header-anchor" href="#文件操作"><span>文件操作</span></a></h3><figure><img src="`+c+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>HDFS 里的文件路径和 Linux 系统一样，也是以 <code>/</code> 作为根目录，可以通过协议头进行区分。但是通常协议头是可以省略的，HDFS 会根据命令类型自动识别路径所指的文件系统，除非不写会有bug或者要强调所在文件系统才需要写明。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Linux</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">file:///usr/local/hello.txt</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># HDFS</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs://127.0.0.1:8020/usr/local/hello.txt</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>关于 HDFS 的操作命令，Hadoop 提供了两套命令系统，除了命令不同，选项参数完全一致。常用操作和 Linux 命令行也很像：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 老版</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hadoop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> fs</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [generic </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">options]</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 新版</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [generic </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">options]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">#  创建目录，-p 自动创建父目录</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -mkdir</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [-p] &lt;path&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 查看目录内容，-h 人性化文件size，-R 递归查看子目录</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -ls</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [-h] [-R] &lt;path&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 查看文件内容。大文件可以用管道配合 more</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -cat</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">sr</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">c&gt; | </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">more</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从本地上传文件到 hdfs，-f 强制覆盖，-p 保留访问和修改时间、所有权和权限</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -put</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [-f] [-p] &lt;localsrc&gt; &lt;dst&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 从 hdfs 下载文件到本地，-f 强制覆盖，-p 保留访问和修改时间、所有权和权限</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -get</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [-f] [-p] &lt;src&gt; &lt;localdst&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 拷贝文件 (hdfs -&gt; hdfs)，-f 强制覆盖</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -cp</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [-f] &lt;src&gt; &lt;dst&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 追加本地数据到 hdfs，如果 localsrc 为 - 则从标准输入读取</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --apendToFile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">localsr</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">c&gt; &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">ds</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">t&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 移动/重命名文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -mv</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">sr</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">c&gt; &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">ds</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">t&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 删除文件，-r 递归删除，-skipTrash 跳过回收站</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 回收站功能默认是关闭的，需要针对每个节点单独配置</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -rm</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -r</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [-skipTrash] &lt;path&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 修改所属用户和组，-R 递归</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -chown</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -R</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> root:root</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">pat</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">h&gt;</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 修改权限</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dfs</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -chmod</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -R</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 777</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">pat</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">h&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><ol><li>HDFS 通过命令只能新增文件、追加数据，不能修改已有数据。想要修改已有数据只能强制覆盖已有的文件。</li><li>除了通过 Shell 命令行方式和 HDFS 交互之外，还可以通过 HDFS 自带的 Web UI 操作文件内容，Jetbrains 系列产品中也有 Big Date Tools 插件可以更方便的操作，HDFS 也支持 NFS (Network File System) 实现本地挂载。</li><li>关于 HDFS 文件的权限，不同于 Linux 系统的超级用户是 root，HDFS 的超级用户是启动 namenode 的用户，root 用户在 HDFS 上并没有特权。</li></ol></blockquote><h3 id="存储原理" tabindex="-1"><a class="header-anchor" href="#存储原理"><span>存储原理</span></a></h3><p>为了统一方便管理，HDFS 设定了统一的管理单元 block 作为最小存储单位，每个占 256MB（可配），并且通过多副本的方式提升了安全性，副本个数可以通过<code>dfs.replication</code>配置。</p><figure><img src="`+o+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># file system check 查看文件信息，包括副本数</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -files 列出路径内的文件状态</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -blocks  输出文件块报告（block 数量，副本数）</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -locations 输出每个 block 详情</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">hdfs</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> fsck</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [-files [-blocks [-locations]]]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在 HDFS 中，文件被划分成一个个 block 块，这些块由集群内的唯一 NameNode 基于<code>edits</code>和<code>fsimage</code>统一管理整个文件系统的。</p><figure><img src="`+y+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>edits 文件记录了 HDFS 中的每一次操作，以及本次操作影响的文件及其对应的 block，因此随着操作增多 edits 文件会逐渐变大，达到上限后会自动开启新的 edits 记录，保证索引性能。</p><figure><img src="'+B+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>但是就跟 Redis 中的 AOF 文件一样，记录所有操作会导致文件检索变慢，因此需要定期（默认3600s/100w次事务）合并所有 edits 生成一个快照，即 fsimage 文件，如果已经存在 fsimage 文件了，那么会自动将所有 edits 和已有的 fsimage 进行合并形成新的 fsimage。</p><figure><img src="'+F+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>而合并元数据这一操作是由辅助角色 SecondaryNameNode 完成的，它会通过 http 从 NameNode 拉取 edits 和 fsimage 进行合并，然后返回给 NameNode 来替换旧的 fsimage。</p><figure><img src="'+v+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="读写过程" tabindex="-1"><a class="header-anchor" href="#读写过程"><span>读写过程</span></a></h3><p><strong>数据写入</strong></p><ol><li>客户端向 NameNode 发起请求</li><li>NameNode 经过各种校验后允许写入，并告知客户端最近的 DataNode 地址</li><li>客户端向指定的 DataNode 发送数据包</li><li>该 DataNode 同时完成数据副本的复制工作，将其接收的数据分发给其它 DataNode</li><li>写入完成后客户端通知 NameNode，NameNode做元数据记录工作</li></ol><figure><img src="'+m+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>客户端直接向1台DataNode写数据，这个DataNode一般是离客户端最近（网络距离）的那一个 数据块副本的复制工作，由DataNode之间自行完成（构建一个PipLine，按顺序复制分发，如图1给2, 2给3和4）</p><p><strong>数据读取</strong></p><ol><li>客户端向 NameNode 申请读取某文件</li><li>NameNode 经过各种校验后允许读取，并返回此文件的 block 列表</li><li>客户端拿到 block 列表后自行寻找 DataNode读取</li></ol><figure><img src="'+u+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>注意细节</strong></p><ul><li>NameNode 不负责实际的数据写入/读取，只负责元数据记录和权限校验，由客户端直连 DataNode 读写数据</li><li>NameNode 会基于 IP 地址、路由表等提供网络距离最近的 DataNode 节点</li></ul><h2 id="mapreduce" tabindex="-1"><a class="header-anchor" href="#mapreduce"><span>MapReduce</span></a></h2><p>MapReduce 是 Hadoop 内提供的进行分布式计算的框架，可供开发人员开发相关程序进行分布式数据计算。所谓分布式计算，就是利用多台机器协同工作，完成对超大数据的计算处理，从计算模式上分为：</p><ul><li><strong>分散-&gt;汇总</strong>: 每台机器各自负责一部分数据分片的处理，然后将各自结果汇总得到结果（MapReduce）</li><li><strong>中心调度-&gt;步骤执行</strong>: 由一个节点作为中心调度者，将任务划分为若干步骤分配给每台机器，最终得到结果（Spark、Flink）</li></ul><p>MapReduce 是<strong>分散-&gt;汇总</strong>模式的分布式计算框架，其提供了两个主要的编程接口：</p><ul><li><strong>Map</strong>：提供了分散功能，由服务器分布式对数据进行处理</li><li><strong>Reduce</strong>：提供了汇总功能，将分布式的处理结果汇总统计</li></ul><p>原理类似 Java 的 Fork-Join 框架，只不过不是交给多线程执行，而是将需求分解为多个 MapTask 和 ReduceTask 并分配到不同的服务器去执行。用户只需要通过某种编程语言实现 Map/Reduce 功能接口即可完成自定义需求的开发，不过由于架构老，性能差，现在很少直接使用了，基本都用更高级的计算框架了，例如 Hive 等。</p><h2 id="yarn" tabindex="-1"><a class="header-anchor" href="#yarn"><span>YARN</span></a></h2><p>YARN 是 Hadoop 内提供的进行分布式资源调度的组件，即管控整个分布式服务器集群的全部资源（内存、CPU等），整合进行统一调度，目的是提高资源的利用率。在集群模式下，MapReduce 需要配合 YARN 进行使用。</p><figure><img src="'+b+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>YARN 也是一种主从架构的设计：</p><ul><li>ResourceManager：整个集群的资源调度者，负责协调调度各个程序所需的资源</li><li>NodeManager：单个服务器的资源调度者，基于容器调度资源，提供给应用程序使用</li></ul><figure><img src="'+D+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>除了核心的主从管理者之外，YARN 还有 2 个辅助角色：</p><ul><li>ProxyServer：Web 应用程序代理，目的是减少通过 YARN 进行网络攻击的可能性</li><li>JobHistoryServer：历史信息记录服务，统一收集各个节点的日志保存到 HDFS</li></ul><p>配置安装过程省略，主要是配置四类角色，然后可以通过脚本启动集群：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 根据配置文件一键启停 ResourceManager -&gt; NodeManager -&gt; ProxyServer</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sbin/start-yarn.sh</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sbin/stop-yarn.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 当前机器单独启停服务</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">bin/yarn</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --daemon</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> start</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">stop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> resourcemanager</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">nodemanager</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">proxyserver</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">bin/mapred</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --daemon</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> start</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">stop</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> historyserver</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="hive" tabindex="-1"><a class="header-anchor" href="#hive"><span>Hive</span></a></h2><p>大数据体系中充斥着非常多的统计分析场景，MapReduce 支持 Java、Python 这类编程语言去处理，但更方便的是用 SQL 进行数据统计，Hive 就是一款可以将 SQL 语句翻译成 MapReduce 程序运行的分布式计算工具。</p><figure><img src="`+f+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>使用 Hive 的好处：</p><ol><li>操作接口采用类SQL语法，简单、容易上手，可以快速开发</li><li>底层执行 MapReduce，可以完成分布式海量数据的 SQL 处理</li></ol><h3 id="基础架构-1" tabindex="-1"><a class="header-anchor" href="#基础架构-1"><span>基础架构</span></a></h3><p>从原理上可以分析出，用 Hive 构建分布式 SQL 计算需要两大功能：</p><ul><li>元数据管理：记录数据位置、数据结构、数据描述等信息</li><li>SQL 解析器：执行 SQL 分析，转化为 MapReduce 程序，提交执行并收集结果</li></ul><p>下面这张图是 Hive 的基础架构，主要的就是在实现这两大功能，具体的组件从左到右包括：</p><ol><li><strong>用户接口</strong>：向用户提供的操作接口</li></ol><ul><li>CLI</li><li>ThriftServer，例如用内置的 beeline 或 DataGrip、Navicat 等工具通过 JDBC/ODBC 协议进行通信</li></ul><ol start="2"><li><strong>Driver</strong>：驱动程序，包括语法解析器、计划编译器、优化器、执行器</li></ol><ul><li>完成对 HQL 语句的词法分析、语法分析、编译、优化，以及查询计划的生成（存储在 HDFS 中等待执行）</li><li>没有具体的服务进程，封装在 Hive 所依赖的 Jar 中</li></ul><ol start="3"><li><strong>MetaStore</strong>：元数据存储</li></ol><ul><li>通常存储在关系数据库（如 mysql、derby）中</li><li>元数据包括表名、字段、分区、属性，以及表的数据所在目录等</li><li>由单独的服务进程维护</li></ul><figure><img src="'+C+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="安装配置-1" tabindex="-1"><a class="header-anchor" href="#安装配置-1"><span>安装配置</span></a></h3><p>Hive 是单机程序，只需部署在一台机器上，但可以提交分布式 MapReduce 任务。同时 Hive 依赖一个关系型数据库系统存储元数据，而 HDFS 数据默认存储在<code>/user/hive/warehouse</code>内。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 启动元数据管理服务</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">bin/hive</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --service</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> metastore</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">nohup</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> bin/hive</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --service</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> metastore</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &gt;&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">logs/metastore.log</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> 2&gt;&amp;1 &amp;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 可选：启动 ThriftServer</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">bin/hive</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --service</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> hiveserver2</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">nohup</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> bin/hive</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --service</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> hiveserver2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &gt;&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">logs/hiveserver2.log</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> 2&gt;&amp;1 &amp;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 启动客户端</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">bin/hive</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>安装过程略...</p><h3 id="基本操作" tabindex="-1"><a class="header-anchor" href="#基本操作"><span>基本操作</span></a></h3><p>执行<code>bin/hive</code>进入 HiveShell 后就可以执行输入 SQL 语句（语法不完全相同）执行。</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" data-title="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 数据库</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">create</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> database</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> if</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> not</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> exists</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> myhive;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">use</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> myhive;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> myhive;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">drop</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> database</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> myhive </span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">[cascade]</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 数据表</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">create</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> test</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(id </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">name</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> STRING, gender STRING) </span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">[location &#39;/myhive2/&#39;]</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">insert into</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> test </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">values</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;王力红&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;男&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), (</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;周杰轮&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;男&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">alter</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> test </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">set</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> TBLPROPERTIES(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;EXTERNAL&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;TRUE&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);  </span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">select</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> gender, </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">COUNT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(*) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> cnt </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> test </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">group by</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> gender;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">desc</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FORMATTED tb1;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">drop</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tablename;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">truncate</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tablename;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 从本地/HDFS导入数据</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">load</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> data</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> [local]</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> inpath </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;path&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> [overwrite]</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> into</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> myhive</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">test_load</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 导出数据到本地/HDFS</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">insert</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> overwrite </span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">[local]</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> directory </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;&lt;path&gt;&#39;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> select</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> * </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> test_load ;</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- hive 执行 SQL 导出</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">bin/hive (-e </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">sql</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | -f </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">sql_file</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;&lt;path&gt;&#39;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 查询语句</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">SELECT</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> [ALL | DISTINCT]</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col_xxx, ...</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">FROM</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tb_xxx</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">WHERE</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> condition</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 支持正则</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">RLIKE reg_pattern</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">GROUP BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">HAVING</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> condition</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">ORDER BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 分桶查询</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">CLUSTER </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 执行 MapReduce 时分配到不同 Reducer</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">DISTRIBUTE </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 排序</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">SORT </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> col</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">LIMIT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> n;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 随机桶抽样</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">SELECT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ... </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">FROM</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tbl TABLESAMPLE(BUCKET x </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">OUT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> OF y </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">ON</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(colname | </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">rand</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()))</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 从前往后采样指定行数/百分比/大小</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">SELECT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ... </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">FROM</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tbl TABLESAMPLE(num </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">ROWS</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | num PERCENT | num(K|M|G));</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="复合字段" tabindex="-1"><a class="header-anchor" href="#复合字段"><span>复合字段</span></a></h4><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" data-title="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- array 类型，item 间 , 分割</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">create</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> myhive</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.test_array(</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    name</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> string, </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    work_locations </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">array</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">string</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">row</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> format delimited fields terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;\\t&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">collection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> items terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;,&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- map 类型，entry 间 # 分割，KV 间 : 分割</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">create</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> myhive</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.test_map(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    id </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    members map</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">string,string</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, age </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">int</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">row</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> format delimited fields terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;,&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">collection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> items terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;#&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">map keys terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;:&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- struct 类型，一列中可以插入多个子列。字段间 # 分割，子列间 : 分割</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">create</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> myhive</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.test_struct(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    id string, </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    info struct</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">name</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:string, age:</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">row</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> format delimited</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">fields terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;#&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">collection</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> items terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;:&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="表类型" tabindex="-1"><a class="header-anchor" href="#表类型"><span>表类型</span></a></h4><p><strong>内部表</strong></p><ul><li>即管理表/普通表，删除内部表会直接删除元数据，因此不适合与其它工具共享数据</li><li>存储位置由<code>hive.metastore.warehouse.dir</code>参数决定，默认<code>/user/hive/warehouse</code></li><li>可以通过<code>alter table tb1 set tblproperties(&#39;EXTERNAL&#39;=&#39;TRUE&#39;)</code>转为外部表</li></ul><p><strong>外部表</strong></p><ul><li>即关联表，通过<code>external</code>指定，删除表时仅删除元数据，不删除数据本身</li><li>外部表和数据是相互独立的，用于临时关联外部数据</li><li>存储位置随意，由<code>LOCATION</code>指定</li></ul><p><strong>分区表</strong></p><p>基于分治的思想，根据<strong>分区列</strong>分区，分区列作为字段存储在 DB 里，但本质上是 HDFS 上的不同文件夹。分区表可以极大的提高特定场景下 Hive 的操作性能。</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" data-title="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 创建分区表</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">create</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> tb1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(...) partitioned </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (分区列 列类型, ...) </span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">row</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> format delimited fields terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 导入数据</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">load</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> data</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> local</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> inpath </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">path</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> into</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tb1 </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">partition</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(分区列</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">xxx, ...);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+E+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>分桶表</strong></p><p>将表拆分到固定数量的不同文件中进行存储，实际上是基于<strong>分桶列</strong>计算 Hash 取模决定分配到哪个桶。分桶表在过滤、JOIN、分组等特定操作下可以带来显著的性能提升。</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" data-title="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 需要先开启分桶的自动优化</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">set</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> hive</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">enforce</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.bucketing</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">true;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 创建分桶表</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">create</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> table</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> tb2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(cid string, cname string) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">clustered</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> by</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(c_id) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">into</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> buckets </span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">row</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> format delimited fields terminated </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;\\t&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 导入数据，由于需要调用 MapReduce 执行哈希计算，所以只能通过 insert select 方式</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">insert</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> overwrite </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">table</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tb2 </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">select</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> * </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tb_common cluster </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">by</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(cid);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="虚拟列" tabindex="-1"><a class="header-anchor" href="#虚拟列"><span>虚拟列</span></a></h4><p>Hive 内置三个特殊标记，用于查询数据本身的详细信息，称为虚拟列，可以像普通列一样被使用：</p><ul><li><code>INPUT__FILE__NAME</code> 显示数据行所在的具体文件</li><li><code>BLOCK__OFFSET__INSIDE__FILE</code> 显示数据行所在文件的偏移量</li><li><code>ROW__OFFSET__INSIDE__BLOCK</code> 显示数据所在HDFS块的偏移量（需设置 hive.exec.rowoffset=true）</li></ul>`,115)),t("p",null,[i[1]||(i[1]=s("更多语句详情见 ")),h(a,{to:"/coding/Hive-SQL.html"},{default:p(()=>i[0]||(i[0]=[s("Hive-SQL")])),_:1})])])}const R=n(S,[["render",x]]),T=JSON.parse('{"path":"/coding/bigdata-hadoop.html","title":"大数据 - Hadoop 概述","lang":"zh-CN","frontmatter":{"title":"大数据 - Hadoop 概述","date":"2023-12-14T00:00:00.000Z","category":["大数据"],"tag":["Hadoop"],"excerpt":"浅学一些大数据的知识，以及 Hadoop 技术栈入门","description":"大数据 人类的行为及产生的事件的一种记录称之为数据，对数据的内容进行深入分析，可以更好的帮助了解事和物在现实世界的运行规律。大数据就是对超大规模的数据进行处理并挖掘出数据背后价值的技术体系，是信息化时代的基础支撑，以数据为生活赋能。 随着科技的发展，大数据技术已经成为从事数据分析、机器学习、人工智能等领域的重要工具。大数据技术涵盖了数据的采集、存储、处...","head":[["meta",{"property":"og:url","content":"https://xchanper.github.io/coding/bigdata-hadoop.html"}],["meta",{"property":"og:site_name","content":"chanper"}],["meta",{"property":"og:title","content":"大数据 - Hadoop 概述"}],["meta",{"property":"og:description","content":"大数据 人类的行为及产生的事件的一种记录称之为数据，对数据的内容进行深入分析，可以更好的帮助了解事和物在现实世界的运行规律。大数据就是对超大规模的数据进行处理并挖掘出数据背后价值的技术体系，是信息化时代的基础支撑，以数据为生活赋能。 随着科技的发展，大数据技术已经成为从事数据分析、机器学习、人工智能等领域的重要工具。大数据技术涵盖了数据的采集、存储、处..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://xchanper.github.io/img/HADOOP-ECOSYSTEM-Edureka.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-22T07:34:10.000Z"}],["meta",{"property":"article:tag","content":"Hadoop"}],["meta",{"property":"article:published_time","content":"2023-12-14T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-22T07:34:10.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"大数据 - Hadoop 概述\\",\\"image\\":[\\"https://xchanper.github.io/img/HADOOP-ECOSYSTEM-Edureka.png\\",\\"https://xchanper.github.io/img/Doug-Cutting.jpg\\",\\"https://xchanper.github.io/img/hdfs架构.png\\",\\"https://xchanper.github.io/img/hdfs%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.png\\",\\"https://xchanper.github.io/img/hdfs%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8.svg\\",\\"https://xchanper.github.io/img/hdfs-namenode.svg\\",\\"https://xchanper.github.io/img/hdfs-edits.svg\\",\\"https://xchanper.github.io/img/hdfs-fsimage.svg\\",\\"https://xchanper.github.io/img/hdfs-fsimage-roll.png\\",\\"https://xchanper.github.io/img/hdfs-%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5.png\\",\\"https://xchanper.github.io/img/hdfs-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96.png\\",\\"https://xchanper.github.io/img/hadoop-yarn调度.svg\\",\\"https://xchanper.github.io/img/hadoop-yarn架构.svg\\",\\"https://xchanper.github.io/img/hadoop-hive%E4%BB%8B%E7%BB%8D.png\\",\\"https://xchanper.github.io/img/hadoop-hive-architectrue.png\\",\\"https://xchanper.github.io/img/hadoop-hive%E5%88%86%E5%8C%BA%E5%88%86%E6%A1%B6.svg\\"],\\"datePublished\\":\\"2023-12-14T00:00:00.000Z\\",\\"dateModified\\":\\"2025-06-22T07:34:10.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"大数据","slug":"大数据","link":"#大数据","children":[{"level":3,"title":"5V 特性","slug":"_5v-特性","link":"#_5v-特性","children":[]},{"level":3,"title":"生态体系","slug":"生态体系","link":"#生态体系","children":[]},{"level":3,"title":"Hadoop","slug":"hadoop","link":"#hadoop","children":[]}]},{"level":2,"title":"HDFS","slug":"hdfs","link":"#hdfs","children":[{"level":3,"title":"基础架构","slug":"基础架构","link":"#基础架构","children":[]},{"level":3,"title":"安装配置","slug":"安装配置","link":"#安装配置","children":[]},{"level":3,"title":"文件操作","slug":"文件操作","link":"#文件操作","children":[]},{"level":3,"title":"存储原理","slug":"存储原理","link":"#存储原理","children":[]},{"level":3,"title":"读写过程","slug":"读写过程","link":"#读写过程","children":[]}]},{"level":2,"title":"MapReduce","slug":"mapreduce","link":"#mapreduce","children":[]},{"level":2,"title":"YARN","slug":"yarn","link":"#yarn","children":[]},{"level":2,"title":"Hive","slug":"hive","link":"#hive","children":[{"level":3,"title":"基础架构","slug":"基础架构-1","link":"#基础架构-1","children":[]},{"level":3,"title":"安装配置","slug":"安装配置-1","link":"#安装配置-1","children":[]},{"level":3,"title":"基本操作","slug":"基本操作","link":"#基本操作","children":[]}]}],"git":{"createdTime":1750577650000,"updatedTime":1750577650000,"contributors":[{"name":"chanper","email":"qianchaosolo@gmail.com","commits":1}]},"filePathRelative":"coding/bigdata-hadoop.md","localizedDate":"2023年12月14日","autoDesc":true}');export{R as comp,T as data};
